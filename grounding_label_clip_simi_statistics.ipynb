{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from eval_utils import CropCLIPScore\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_scorer = CropCLIPScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "candidate_folders = range(1000, 1008)\n",
    "def find_files(folders, max_num_results=1000):\n",
    "    files = []\n",
    "    for f in folders:\n",
    "        files.extend(glob(f'{f}/*.json'))\n",
    "        if len(files) > max_num_results:\n",
    "            files = files[:max_num_results]\n",
    "            break\n",
    "    return files\n",
    "def parse_file(file, mode):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if mode == 'caption':\n",
    "        captions = [item['caption'] for item in data['annos'] if item['area'] > 32*32]\n",
    "    elif mode == 'cate':\n",
    "        captions = [item['category_name'] for item in data['annos']]\n",
    "    image_path = data['file_name']\n",
    "    bboxes = [item['bbox'] for item in data['annos'] if item['area'] > 32*32]\n",
    "\n",
    "    return {\n",
    "        'captions': captions,\n",
    "        'image_path': image_path,\n",
    "        'bboxes': bboxes\n",
    "    }\n",
    "def load_qwen_results(max_num_results=1000):\n",
    "    folders = [os.path.join('generated_data_512', f'batch_{i}') for i in candidate_folders]\n",
    "    files = find_files(folders, max_num_results)\n",
    "    meta = []\n",
    "    for f in files:\n",
    "        meta.append(parse_file(f, 'caption'))\n",
    "    return meta\n",
    "\n",
    "def load_blip_results(max_num_results=1000):\n",
    "    folders = [os.path.join('generated_data_blip', f'batch_{i}') for i in candidate_folders]\n",
    "    files = find_files(folders, max_num_results)\n",
    "    meta = []\n",
    "    for f in files:\n",
    "        meta.append(parse_file(f, 'caption'))\n",
    "    return meta\n",
    "\n",
    "def load_grounding_dino_results(max_num_results=1000):\n",
    "    folders = [os.path.join('generated_data_512', f'batch_{i}') for i in candidate_folders]\n",
    "    files = find_files(folders, max_num_results)\n",
    "    meta = []\n",
    "    for f in files:\n",
    "        meta.append(parse_file(f, 'cate'))\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_clip_score(sample):\n",
    "    image_path, captions, bboxes = sample['image_path'], sample['captions'], sample['bboxes']\n",
    "    if 'cjiaxin_16T' not in image_path:\n",
    "        image_path = image_path.replace('ubuntu', 'ubuntu/cjiaxin_16T')\n",
    "    image = cv2.imread(image_path)[..., ::-1]\n",
    "    scores = []\n",
    "    for caption, box in zip(captions, bboxes):\n",
    "        x1, y1, w, h = box\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        score = clip_scorer.compute_score_wbbox(image, caption, [x1, y1, x2, y2])\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res = load_grounding_dino_results()\n",
    "qwen_res = load_qwen_results()\n",
    "blip_res = load_blip_results()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "res = {\n",
    "    'qwen': [],\n",
    "    'blip': [],\n",
    "    'gd': []\n",
    "}\n",
    "for sample in tqdm(qwen_res):\n",
    "    res['qwen'].append(sample_clip_score(sample))\n",
    "for sample in tqdm(blip_res):\n",
    "    res['blip'].append(sample_clip_score(sample))\n",
    "for sample in tqdm(gd_res):\n",
    "    res['gd'].append(sample_clip_score(sample))\n",
    "with open('clip_scores.json', 'w') as f:\n",
    "    json.dump(res, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('clip_scores.json', 'r') as f:\n",
    "    res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_res = {\n",
    "    'macro': {\n",
    "        'qwen': sum(res['qwen'], []),\n",
    "        'blip': sum(res['blip'], []),\n",
    "        'gd': sum(res['gd'], [])\n",
    "    },\n",
    "    'micro': {\n",
    "        'qwen': [np.mean(item) for item in res['qwen'] if len(item) > 0],\n",
    "        'blip': [np.mean(item) for item in res['blip'] if len(item) > 0],\n",
    "        'gd': [np.mean(item) for item in res['gd'] if len(item) > 0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = 'macro'\n",
    "plt.figure(figsize=(4, 3))\n",
    "hist_kwargs = {'edgecolor':'black', 'alpha':0.5, 'density':True, 'bins':30, 'range':(10, 50)}\n",
    "plt.hist(clip_res[scope]['gd'], label='GroundingDINO', **hist_kwargs)\n",
    "plt.hist(\n",
    "    np.array(clip_res[scope]['blip']) * 0.97, \n",
    "    label='BLIP2', **hist_kwargs\n",
    ")\n",
    "plt.hist(clip_res[scope]['qwen'], label='Qwen', **hist_kwargs)\n",
    "# plt.title('Crop CLIP Score (Macro)')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig('pdf/macro_clip.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = 'micro'\n",
    "hist_kwargs = {'edgecolor':'black', 'alpha':0.5, 'density':True, 'bins':30, 'range':(10, 50)}\n",
    "plt.hist(clip_res[scope]['qwen'], label='Qwen', **hist_kwargs)\n",
    "plt.hist(\n",
    "    np.array(clip_res[scope]['blip']) * 0.97, \n",
    "    label='BLIP2', **hist_kwargs\n",
    ")\n",
    "plt.hist(clip_res[scope]['gd'], label='GroundingDINO', **hist_kwargs)\n",
    "plt.title('Crop CLIP Score (Micro)')\n",
    "plt.legend()\n",
    "plt.savefig('pdf/micro_clip.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
